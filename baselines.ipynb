{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "import torch\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for english!!!\n",
    "LABELS = [i for i in range(26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    '''Function for locking the random seed. Used to compare models in equal conditions.'''\n",
    "    \n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['PL_GLOBAL_SEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recolor(picture_path):\n",
    "    '''Replaces line color with magenta and makes backgroud black.'''\n",
    "    \n",
    "    picture = Image.open(picture_path)\n",
    "    width, height = picture.size\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            current_color = picture.getpixel((x, y))\n",
    "            if current_color[-1] != 0:\n",
    "                picture.putpixel((x,y), (255, 0, 255, 255))\n",
    "            else:\n",
    "                picture.putpixel((x,y), (0, 0, 0, 255))\n",
    "    \n",
    "    picture.save(picture_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    '''Shows image of given tensor.'''\n",
    "    \n",
    "    inp = inp.permute(1, 2, 0).numpy()\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    #plt.figure(figsize=(16, 9))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=25, device='cuda', savename=None, verbose=2, class_labels=LABELS):\n",
    "    '''Performs basic model training\n",
    "        verbose: 0 for complete abscence of text during training, 1 for showing only main pbar, 2 for full info\n",
    "    '''\n",
    "    \n",
    "    losses = {'train': [], 'val': []}\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "    roc_aucs = {'train': [], 'val': []}\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_roc_auc = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "    \n",
    "    model.to(device)\n",
    "    pbar = trange(num_epochs, desc='Epoch', disable=(verbose == 0))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in pbar:\n",
    "        epoch_probas, epoch_labels = {'train': torch.tensor([]), 'val': torch.tensor([])}, {'train': torch.tensor([]), 'val': torch.tensor([])}\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            train_pbar = tqdm(dataloaders[phase], leave=True, desc=f'{phase} iter', disable=(verbose < 2))\n",
    "            for data in train_pbar:\n",
    "                \n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    with torch.inference_mode():\n",
    "                        outputs = model(inputs)\n",
    "                \n",
    "                preds = torch.argmax(outputs, -1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                epoch_probas[phase] = torch.cat((epoch_probas[phase], outputs.cpu().detach().float()))\n",
    "                epoch_labels[phase] = torch.cat((epoch_labels[phase], labels.cpu()))\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                running_corrects += int(torch.sum(preds == labels).item())\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            epoch_roc_auc = roc_auc_score(epoch_labels[phase].numpy(), epoch_probas[phase].numpy(), multi_class='ovo', labels=class_labels)\n",
    "            \n",
    "            losses[phase].append(epoch_loss)\n",
    "            accuracies[phase].append(epoch_acc)\n",
    "            roc_aucs[phase].append(epoch_roc_auc)\n",
    "            pbar.set_description(f'{phase} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f} RocAuc: {epoch_roc_auc:.4f}')\n",
    "            if epoch_roc_auc > best_roc_auc:\n",
    "                best_roc_auc = epoch_roc_auc\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                if savename:\n",
    "                    best_model_wts = model.state_dict()\n",
    "                    torch.save(model.state_dict(), 'models/' + savename)\n",
    "    \n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Training complete in {time_elapsed // 60}m {(time_elapsed % 60):.4f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "    print(f'Best val Roc-Auc: {best_roc_auc:.4f}')\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, losses, accuracies, roc_aucs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, testloader, device='cuda', class_labels=LABELS):\n",
    "    '''Evaluates given model. Returns accuracy, roc_auc_score, presicion and recall.'''\n",
    "    \n",
    "    model.eval()\n",
    "    objects_processed = 0\n",
    "    runninig_correct = []\n",
    "    probas_val, labels_val, preds_val = torch.tensor([]), torch.tensor([]), torch.tensor([])\n",
    "    for data in testloader:\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        objects_processed += len(labels)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, -1)\n",
    "        runninig_correct.append(int(torch.sum(preds == labels)))\n",
    "        \n",
    "        preds_val = torch.cat((preds_val, preds.cpu()))\n",
    "        probas_val = torch.cat((probas_val, outputs.cpu().detach().float()))\n",
    "        labels_val = torch.cat((labels_val, labels.cpu()))\n",
    "    \n",
    "    return (sum(runninig_correct) / objects_processed,\n",
    "            roc_auc_score(labels_val.numpy(), probas_val.numpy(), multi_class='ovo', labels=class_labels),\n",
    "            precision_score(labels_val.numpy(), preds_val.numpy(), average='macro', labels=class_labels),\n",
    "            recall_score(labels_val.numpy(), preds_val.numpy(), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plot(losses, accuracies, roc_aucs):\n",
    "    '''Makes plots of loss, accuracy and roc auc score changes with epochs'''\n",
    "    \n",
    "    sns.set(style='darkgrid', font_scale=1.4)\n",
    "    # losses\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(losses['train'], label='train', linewidth=4, color='blue')\n",
    "    plt.plot(losses['val'], label='validation', linewidth=4, color='red')\n",
    "    plt.axhline(y=min(losses['train']), linewidth=3, linestyle='--', color='blue')\n",
    "    plt.axhline(y=min(losses['val']), linewidth=3, linestyle='--', color='red')\n",
    "    plt.axvline(x=losses['train'].index(min(losses['train'])), label='min on train', linewidth=3, linestyle='--', color='blue')\n",
    "    plt.axvline(x=losses['val'].index(min(losses['val'])), label='min on validation', linewidth=3, linestyle='--', color='red')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # accuracies\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(accuracies['train'], label='train', linewidth=4, color='blue')\n",
    "    plt.plot(accuracies['val'], label='validation', linewidth=4, color='red')\n",
    "    plt.axhline(y=max(accuracies['train']), linewidth=3, linestyle='--', color='blue')\n",
    "    plt.axhline(y=max(accuracies['val']), linewidth=3, linestyle='--', color='red')\n",
    "    plt.axvline(x=accuracies['train'].index(max(accuracies['train'])), label='max on train', linewidth=3, linestyle='--', color='blue')\n",
    "    plt.axvline(x=accuracies['val'].index(max(accuracies['val'])), label='max on validation', linewidth=3, linestyle='--', color='red')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # roc auc scores\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(roc_aucs['train'], label='train', linewidth=4, color='blue')\n",
    "    plt.plot(roc_aucs['val'], label='validation', linewidth=4, color='red')\n",
    "    plt.axhline(y=max(roc_aucs['train']), linewidth=3, linestyle='--', color='blue')\n",
    "    plt.axhline(y=max(roc_aucs['val']), linewidth=3, linestyle='--', color='red')\n",
    "    plt.axvline(x=roc_aucs['train'].index(max(roc_aucs['train'])), label='max on train', linewidth=3, linestyle='--', color='blue')\n",
    "    plt.axvline(x=roc_aucs['val'].index(max(roc_aucs['val'])), label='max on validation', linewidth=3, linestyle='--', color='red')\n",
    "    plt.title('Roc Auc Score')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['dimgray', 'indianred', 'red', 'sienna', 'sandybrown', 'darkorange', 'moccasin', 'gold', 'darkkhaki', 'yellowgreen',\\\n",
    "                'seagreen', 'turquoise', 'aqua', 'deepskyblue', 'midnightblue', 'blue', 'darkviolet', 'violet', 'hotpink']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plots(losses, accuracies, model_names, num_epochs=25, titles=['Losses on val', 'Accuracies on val'], linestyle='-'):\n",
    "    '''Shows comaparison plots of accuracies and losses for all models.'''\n",
    "    \n",
    "    sns.set(style='darkgrid', font_scale=1.4)\n",
    "    colormap = plt.cm.seismic\n",
    "    colors = [colormap(int(i * colormap.N / len(losses))) for i in range(len(losses))]\n",
    "    \n",
    "    # losses\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    for i, model in enumerate(losses):\n",
    "        plt.plot(model['val'], label=model_names[i], linewidth=4, color=colors[i], linestyle=linestyle)\n",
    "        plt.xticks(np.arange(0, num_epochs, 1), labels=[str(i + 1) for i in range(num_epochs)])\n",
    "    plt.title(titles[0])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # accuracies\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for i, model in enumerate(accuracies):\n",
    "        plt.plot(model['val'], label=model_names[i], linewidth=4, color=colors[i], linestyle=linestyle)\n",
    "        plt.xticks(np.arange(0, num_epochs, 1), labels=[str(i + 1) for i in range(num_epochs)])\n",
    "    plt.title(titles[1])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data, file_names):\n",
    "    for name, data in zip(file_names, data):\n",
    "        with open('pickled/' + name + '.pickle', 'wb') as handler:\n",
    "            pickle.dump(data, handler, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load(file_names):\n",
    "    output = []\n",
    "    for name in file_names:\n",
    "        with open('pickled/' + name + '.pickle', 'rb') as handler:\n",
    "            output.append(pickle.load(handler))\n",
    "    \n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
